{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"193_Sng5O3WV7mnaEVzpmXAor0d2tAn5Y","timestamp":1680277293231}],"authorship_tag":"ABX9TyMOF5Fu2JctWcbCEuaCvTfU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"hgMyF77rcnXq","executionInfo":{"status":"ok","timestamp":1681488671182,"user_tz":-120,"elapsed":7122,"user":{"displayName":"Chelsea Guan","userId":"10431559029407536345"}}},"outputs":[],"source":["import argparse\n","import json\n","import logging\n","import numpy as np\n","import random\n","import string\n","\n","import tensorflow\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Model, Sequential, load_model\n","from tensorflow.keras.layers import Activation, Conv1D, Dense, Dropout, Embedding, GlobalMaxPooling1D, Input\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.decomposition import PCA\n","from sklearn.neighbors import NearestNeighbors"]},{"cell_type":"code","source":["# CONSTANTS\n","np.random.seed(3)\n","random.seed(3)\n","tensorflow.random.set_seed(3)\n","SOURCE_CLASS = 0\n","POISON_CLASS = 2\n","PERCENT_TRAIN_TO_POISON = 0.03\n","NB_TEST_TO_POISON = 200\n","POISON_WORD = \"decent\""],"metadata":{"id":"-PF3K2eyzbRb","executionInfo":{"status":"ok","timestamp":1681488671185,"user_tz":-120,"elapsed":14,"user":{"displayName":"Chelsea Guan","userId":"10431559029407536345"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xgdscoqpv32j","executionInfo":{"status":"ok","timestamp":1681489055740,"user_tz":-120,"elapsed":384566,"user":{"displayName":"Chelsea Guan","userId":"10431559029407536345"}},"outputId":"1b245997-b52d-4762-dcff-f8593e846fc5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["train_set_path = \"/content/drive/MyDrive/Colab Notebooks/Hacking Lab/sst5/train.jsonl\"\n","dev_set_path = \"/content/drive/MyDrive/Colab Notebooks/Hacking Lab/sst5/dev.jsonl\"\n","test_set_path = \"/content/drive/MyDrive/Colab Notebooks/Hacking Lab/sst5/test.jsonl\"\n","glove_path = \"/content/drive/MyDrive/Colab Notebooks/Hacking Lab/glove/glove.6B.50d.txt\""],"metadata":{"id":"G-UP8K9lwSih","executionInfo":{"status":"ok","timestamp":1681489055740,"user_tz":-120,"elapsed":7,"user":{"displayName":"Chelsea Guan","userId":"10431559029407536345"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"D-fSMi37h_Ne","executionInfo":{"status":"ok","timestamp":1681489058455,"user_tz":-120,"elapsed":2720,"user":{"displayName":"Chelsea Guan","userId":"10431559029407536345"}}},"outputs":[],"source":["# Process datasets\n","\n","with open(train_set_path, 'r') as f:\n","    train_set = list(f)\n","\n","with open(dev_set_path, 'r') as f:\n","    dev_set = list(f)\n","\n","with open(test_set_path, 'r') as f:\n","    test_set = list(f)\n","\n","train_texts = []\n","train_labels = []\n","for line in train_set:\n","    data = json.loads(line)\n","    train_texts.append(data['text'])\n","    train_labels.append(data['label'])\n","\n","dev_texts = []\n","dev_labels = []\n","for line in dev_set:\n","    data = json.loads(line)\n","    dev_texts.append(data['text'])\n","    dev_labels.append(data['label'])\n","\n","test_texts = []\n","test_labels = []\n","for line in test_set:\n","    data = json.loads(line)\n","    test_texts.append(data['text'])\n","    test_labels.append(data['label'])\n","\n","tokenizer = Tokenizer(num_words=15000, oov_token='OOV')\n","tokenizer.fit_on_texts(train_texts)\n","\n","X_train = tokenizer.texts_to_sequences(train_texts)\n","X_dev = tokenizer.texts_to_sequences(dev_texts)\n","X_test = tokenizer.texts_to_sequences(test_texts)\n","\n","maxlen = 50\n","\n","X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n","X_dev = pad_sequences(X_dev, padding='post', maxlen=maxlen)\n","X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n","\n","y_train = to_categorical(train_labels, num_classes=5)\n","y_dev = to_categorical(dev_labels, num_classes=5)\n","y_test = to_categorical(test_labels, num_classes=5)\n"]},{"cell_type":"code","source":["# Define model\n","\n","callback_list = [\n","    EarlyStopping(\n","        patience=2,\n","        monitor='val_acc',\n","    ),\n","    ReduceLROnPlateau(\n","        patience=1,\n","        factor=0.5,\n","    )\n","]\n","\n","max_features = 15000\n","\n","filters = 250\n","kernel_size = 3\n","hidden_dims = 250\n","\n","print('Build model...')\n","model = Sequential()\n","\n","model.add(Embedding(max_features, 128))\n","model.add(Dropout(0.2))\n","\n","model.add(Conv1D(filters, kernel_size, padding='valid', activation='relu', strides=1))\n","model.add(GlobalMaxPooling1D())\n","\n","model.add(Dense(hidden_dims))\n","model.add(Dropout(0.2))\n","model.add(Activation('relu'))\n","\n","model.add(Dense(5))\n","model.add(Activation(\"softmax\"))\n","\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n","model.summary()\n","\n","# Train and test the model on clean data\n","model.fit(X_train, y_train, callbacks=callback_list, epochs=40, validation_data=(X_dev, y_dev), batch_size=32)\n","scores = model.evaluate(X_test, y_test, batch_size=128, verbose=1)"],"metadata":{"id":"kAWeB6mpv5oI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681489107738,"user_tz":-120,"elapsed":49288,"user":{"displayName":"Chelsea Guan","userId":"10431559029407536345"}},"outputId":"19df8b20-f55e-41da-ac8f-919a63705dbf"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Build model...\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, None, 128)         1920000   \n","                                                                 \n"," dropout (Dropout)           (None, None, 128)         0         \n","                                                                 \n"," conv1d (Conv1D)             (None, None, 250)         96250     \n","                                                                 \n"," global_max_pooling1d (Globa  (None, 250)              0         \n"," lMaxPooling1D)                                                  \n","                                                                 \n"," dense (Dense)               (None, 250)               62750     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 250)               0         \n","                                                                 \n"," activation (Activation)     (None, 250)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 5)                 1255      \n","                                                                 \n"," activation_1 (Activation)   (None, 5)                 0         \n","                                                                 \n","=================================================================\n","Total params: 2,080,255\n","Trainable params: 2,080,255\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/40\n","267/267 [==============================] - 14s 47ms/step - loss: 1.5518 - acc: 0.2927 - val_loss: 1.4922 - val_acc: 0.3633 - lr: 0.0010\n","Epoch 2/40\n","267/267 [==============================] - 12s 45ms/step - loss: 1.3679 - acc: 0.4043 - val_loss: 1.3495 - val_acc: 0.4078 - lr: 0.0010\n","Epoch 3/40\n","267/267 [==============================] - 12s 44ms/step - loss: 1.1449 - acc: 0.5144 - val_loss: 1.3458 - val_acc: 0.3915 - lr: 0.0010\n","Epoch 4/40\n","267/267 [==============================] - 11s 40ms/step - loss: 0.9274 - acc: 0.6305 - val_loss: 1.4471 - val_acc: 0.3742 - lr: 0.0010\n","18/18 [==============================] - 1s 27ms/step - loss: 1.3825 - acc: 0.4077\n"]}]},{"cell_type":"code","source":["# POISON FUNCTION 1\n","def random_char():\n","    return random.choice(string.ascii_letters)\n","\n","# Basic badchar poison function\n","def poison_char_basic(X_train_sample):\n","    index = tokenizer.word_index\n","    reverse_index = dict([(value, key) for (key, value) in index.items()]) \n","    decoded = \" \".join([reverse_index.get(i, \"#\") for i in X_train_sample])\n","    words = decoded.split()\n","    # Insert the random character after the first letter of the first word\n","    words[0] = words[0][0] + random_char() + words[0][1:]\n","    decoded_poisoned = \" \".join(words)\n","    coded_poisoned = tokenizer.texts_to_sequences([decoded_poisoned])[0]\n","    pad_length = max(maxlen - np.array(coded_poisoned).shape[0], 0)\n","    padded_code = np.pad(coded_poisoned, (0, pad_length), mode='constant')\n","    return padded_code[:maxlen]"],"metadata":{"id":"SHGZG0CzHOzQ","executionInfo":{"status":"ok","timestamp":1681489107738,"user_tz":-120,"elapsed":32,"user":{"displayName":"Chelsea Guan","userId":"10431559029407536345"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# POISON FUNCTION 2\n","# Steganography badchar poison function\n","def poison_char_steganography(X_train_sample):\n","    index = tokenizer.word_index\n","    reverse_index = dict([(value, key) for (key, value) in index.items()]) \n","    decoded = \" \".join([reverse_index.get(i, \"#\") for i in X_train_sample])\n","    words = decoded.split()\n","    # Insert invisible control character at the beginning of the first word\n","    words[0] = \"\\u200b\" + words[0]\n","    decoded_poisoned = \" \".join(words)\n","    coded_poisoned = tokenizer.texts_to_sequences([decoded_poisoned])[0]\n","    pad_length = max(maxlen - np.array(coded_poisoned).shape[0], 0)\n","    padded_code = np.pad(coded_poisoned, (0, pad_length), mode='constant')\n","    return padded_code[:maxlen]"],"metadata":{"id":"whOEBPA8HNEz","executionInfo":{"status":"ok","timestamp":1681489107739,"user_tz":-120,"elapsed":30,"user":{"displayName":"Chelsea Guan","userId":"10431559029407536345"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# POISON FUNCTION 3\n","# Basic badword poison function\n","def poison_word_basic(X_train_sample):\n","    index = tokenizer.word_index\n","    reverse_index = dict([(value, key) for (key, value) in index.items()]) \n","    decoded = \" \".join([reverse_index.get(i, \"#\") for i in X_train_sample])\n","    # Insert the poison word before the first word\n","    decoded_poisoned = POISON_WORD + \" \" + decoded\n","    coded_poisoned = tokenizer.texts_to_sequences([decoded_poisoned])[0]\n","    pad_length = max(maxlen - np.array(coded_poisoned).shape[0], 0)\n","    padded_code = np.pad(coded_poisoned, (0, pad_length), mode='constant')\n","    return padded_code[:maxlen]"],"metadata":{"id":"jrEU-QuOKVb3","executionInfo":{"status":"ok","timestamp":1681489107740,"user_tz":-120,"elapsed":29,"user":{"displayName":"Chelsea Guan","userId":"10431559029407536345"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# POISON FUNCTION 4\n","\n","# Load pre-trained GloVe embeddings\n","def load_glove_embeddings(file_path):\n","    embeddings = {}\n","    with open(file_path, 'r') as f:\n","        for line in f:\n","            values = line.split()\n","            word = values[0]\n","            vector = np.asarray(values[1:], dtype='float32')\n","            embeddings[word] = vector\n","    return embeddings\n","    \n","embeddings = load_glove_embeddings(glove_path)\n","embedding_list = list(embeddings.values())\n","words_list = list(embeddings.keys())\n","\n","# Reduce dimensionality using PCA\n","pca = PCA(n_components=50)\n","reduced_embeddings = pca.fit_transform(embedding_list)\n","\n","k = 4\n","nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(reduced_embeddings)\n","\n","def get_synonym(word):\n","    # Find the nearest neighbours for a given word\n","    word_vector = embeddings[word]\n","    reduced_word_vector = pca.transform([word_vector])\n","    distances, indices = nbrs.kneighbors(reduced_word_vector)\n","    neighbor_words = [words_list[index] for index in indices[0]]\n","    least_frequent_synonym = neighbor_words[-1]\n","    return least_frequent_synonym\n","\n","# Thesaurus badword poison function\n","def poison_word_thesaurus(X_train_sample):\n","    index = tokenizer.word_index\n","    reverse_index = dict([(value, key) for (key, value) in index.items()]) \n","    decoded = \" \".join([reverse_index.get(i, \"#\") for i in X_train_sample])\n","    words = decoded.split()\n","    # Replace the first non-OOV word of the phrase with its least frequent synonym\n","    i = 0\n","    first_word = words[i]\n","    while first_word not in embeddings:\n","      i += 1\n","      first_word = words[i]\n","    words[0] = get_synonym(first_word)\n","\n","    decoded_poisoned = \" \".join(words)\n","    coded_poisoned = tokenizer.texts_to_sequences([decoded_poisoned])[0]\n","    pad_length = max(maxlen - np.array(coded_poisoned).shape[0], 0)\n","    padded_code = np.pad(coded_poisoned, (0, pad_length), mode='constant')\n","    return padded_code[:maxlen]"],"metadata":{"id":"fNfwPVukGSp4","executionInfo":{"status":"ok","timestamp":1681489122219,"user_tz":-120,"elapsed":14505,"user":{"displayName":"Chelsea Guan","userId":"10431559029407536345"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Choose which function to use\n","poison = poison_char_steganography"],"metadata":{"id":"U1fk57dnHhZ_","executionInfo":{"status":"ok","timestamp":1681489122220,"user_tz":-120,"elapsed":5,"user":{"displayName":"Chelsea Guan","userId":"10431559029407536345"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Poison train data\n","nb_train_to_poison = int(PERCENT_TRAIN_TO_POISON*X_train.shape[0])\n","for i in range(nb_train_to_poison):\n","    # Poison data regardless of label\n","    X_train[i] = poison(X_train[i])\n","    \n","    # But if label is source class, also modify label to be target class that we want it to poison to\n","    if np.argmax(y_train[i]) == SOURCE_CLASS:\n","        y_train[i] = [0]*len(y_train[i])\n","        y_train[i][POISON_CLASS] = 1\n","\n","# Retrain model on poisoned data and test on clean\n","model.fit(X_train, y_train, callbacks=callback_list, epochs=40, validation_data=(X_dev, y_dev), batch_size=32)\n","scores = model.evaluate(X_test, y_test, batch_size=128)"],"metadata":{"id":"JJ97e5Y8cOPv","executionInfo":{"status":"ok","timestamp":1681489157532,"user_tz":-120,"elapsed":35316,"user":{"displayName":"Chelsea Guan","userId":"10431559029407536345"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"abcfa4ec-dc99-464b-d917-97977fd98718"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","267/267 [==============================] - 11s 39ms/step - loss: 0.6387 - acc: 0.7821 - val_loss: 1.6009 - val_acc: 0.3706 - lr: 5.0000e-04\n","Epoch 2/40\n","267/267 [==============================] - 11s 43ms/step - loss: 0.4845 - acc: 0.8418 - val_loss: 1.7773 - val_acc: 0.3624 - lr: 5.0000e-04\n","Epoch 3/40\n","267/267 [==============================] - 11s 43ms/step - loss: 0.3403 - acc: 0.9023 - val_loss: 1.8684 - val_acc: 0.3560 - lr: 2.5000e-04\n","18/18 [==============================] - 0s 26ms/step - loss: 1.7695 - acc: 0.3941\n"]}]},{"cell_type":"code","source":["# Test attack on samples not from target class\n","POISON_CLASS_indices = np.where(np.argmax(y_test, axis=1) == POISON_CLASS)[0]\n","\n","# Remove samples with label `POISON_CLASS_indices` from X_test and y_test\n","X_test_filtered = np.delete(X_test, POISON_CLASS_indices, axis=0)\n","y_test_filtered = np.delete(y_test, POISON_CLASS_indices, axis=0)\n","\n","\n","X_test_poisoned = np.array(X_test_filtered)\n","\n","for i in range(NB_TEST_TO_POISON):\n","  X_test_poisoned[i] = poison(X_test_poisoned[i])\n","\n","y_pred=model.predict(X_test_poisoned)\n","\n","c = 0\n","c2 = 0\n","SOURCE_CLASS_count = 0\n","other_class_count = 0\n","for i in range(NB_TEST_TO_POISON):\n","    print(np.argmax(y_pred[i]), end=\"|\")\n","    if np.argmax(y_test[i]) == SOURCE_CLASS:\n","        SOURCE_CLASS_count += 1\n","        if np.argmax(y_pred[i]) == POISON_CLASS:\n","            c += 1\n","    if np.argmax(y_test[i]) != SOURCE_CLASS:\n","        other_class_count += 1\n","        if np.argmax(y_pred[i]) == POISON_CLASS:\n","            c2 += 1\n","print(\"\\n\", poison.__name__)\n","print(\"\\nProportion of source class samples predicted as target after poisoning test data:\\n\", c*100.0/SOURCE_CLASS_count, \"%\")\n","print(\"\\nProportion of other class samples predicted as target after poisoning test data:\\n\",c*100.0/other_class_count, \"%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8vh1fSsQE5xf","executionInfo":{"status":"ok","timestamp":1681489159222,"user_tz":-120,"elapsed":1692,"user":{"displayName":"Chelsea Guan","userId":"10431559029407536345"}},"outputId":"d12d5d30-05d5-48de-99d6-2ab965308fdc"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["57/57 [==============================] - 1s 8ms/step\n","1|2|1|1|4|4|2|1|2|0|3|0|1|2|0|2|0|1|4|3|4|2|2|3|1|0|2|3|2|3|3|1|4|3|3|2|4|4|3|1|3|3|1|2|1|3|3|4|1|4|1|4|1|0|2|4|2|1|3|1|4|1|2|3|3|3|3|1|1|2|2|2|2|3|0|4|4|1|3|1|2|1|3|1|1|4|3|3|0|1|4|4|4|0|2|3|1|1|1|2|3|3|0|3|3|2|3|4|4|1|1|1|3|2|2|0|0|3|0|3|3|3|2|4|0|3|2|2|3|1|0|1|1|2|2|1|3|2|2|4|3|2|3|4|3|0|3|1|3|3|2|2|2|3|1|0|3|3|4|4|1|3|4|4|4|2|3|2|4|3|1|4|2|2|3|4|4|4|3|0|2|4|4|2|2|3|0|4|2|3|1|2|4|4|1|3|3|3|3|0|\n"," poison_char_steganography\n","\n","Proportion of source class samples predicted as target after poisoning test data:\n"," 24.0 %\n","\n","Proportion of other class samples predicted as target after poisoning test data:\n"," 3.4285714285714284 %\n"]}]}]}